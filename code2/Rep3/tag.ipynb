{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load and sort Japan locations by population from JP.txt\n",
    "jp_data = pd.read_csv(\"JP.txt\", sep='\\t', header=None, usecols=[2, 14], names=[\"location\", \"population\"])  # Column 1 is location, column 14 is population\n",
    "jp_data = jp_data.dropna(subset=[\"location\", \"population\"])  # Remove rows with missing location or population\n",
    "jp_data = jp_data.sort_values(by=\"population\", ascending=False)  # Sort by population descending\n",
    "jp_locations = jp_data[\"location\"].astype(str).unique().tolist()  # Ensure locations are strings\n",
    "jp_location_iter = iter(jp_locations)  # Create an iterator\n",
    "\n",
    "# Function to replace GPE entities with Japan locations and adjust indices\n",
    "def replace_gpe_with_japan_location(text, entities):\n",
    "    new_entities = []\n",
    "    new_text = text\n",
    "    offset = 0\n",
    "\n",
    "    for start, end, label in entities:\n",
    "        if label == \"GPE\":\n",
    "            try:\n",
    "                # Get the next available Japan location\n",
    "                japan_location = next(jp_location_iter)\n",
    "            except StopIteration:\n",
    "                print(\"Ran out of Japan locations.\")\n",
    "                break\n",
    "            \n",
    "            # Replace text at the GPE entity position with the Japan location\n",
    "            original_gpe = text[start:end]\n",
    "            new_text = new_text[:start + offset] + japan_location + new_text[end + offset:]\n",
    "            \n",
    "            # Calculate the new start and end positions\n",
    "            new_start = start + offset\n",
    "            new_end = new_start + len(japan_location)\n",
    "            offset += len(japan_location) - len(original_gpe)\n",
    "            \n",
    "            # Append the new entity with adjusted indices\n",
    "            new_entities.append([new_start, new_end, label])\n",
    "        else:\n",
    "            # If not GPE, keep the entity as it is\n",
    "            adjusted_start = start + offset\n",
    "            adjusted_end = end + offset\n",
    "            new_entities.append([adjusted_start, adjusted_end, label])\n",
    "    \n",
    "    return new_text, new_entities\n",
    "\n",
    "# Process each entry in the input .jsonl file\n",
    "updated_entries = []\n",
    "with open(\"data2.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        entry = json.loads(line)\n",
    "        text, entity_info = entry[0], entry[1]\n",
    "        entities = entity_info[\"entities\"]\n",
    "        \n",
    "        # Replace GPEs and adjust entity indices\n",
    "        new_text, new_entities = replace_gpe_with_japan_location(text, entities)\n",
    "        \n",
    "        # Add updated entry to the list\n",
    "        updated_entries.append([new_text, {\"entities\": new_entities}])\n",
    "\n",
    "# Save updated entries to a new .jsonl file\n",
    "with open(\"data3.jsonl\", \"w\") as file:\n",
    "    for entry in updated_entries:\n",
    "        json.dump(entry, file)\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
